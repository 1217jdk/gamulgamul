{
  "metadata": {
    "name": "2_goods_id의_product_id_수정_(탕종숙식빵)",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 6g\n\n# set executor number to be 3\nspark.executor.instances  4\n\n# set executor memory 4g\nspark.executor.memory  2g\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 1. goodsId_productId_pickle_수정\n+ 탕종숙식빵(420g)(goods_id\u003d94) 의 product를 빵(product_id\u003d34)-\u003e 식빵(product_id\u003d37)으로 수정\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pandas as pd\nimport pickle\n# goodsId_productId.pickle 수정\n\n\n# 1. pickle load 후, 데이터 교체\nwith open(\u0027/DB_data/goodsId_productId.pickle\u0027, \u0027rb\u0027) as fr:\n    goodsId_productId \u003d pickle.load(fr)\nprint(\u0027교체 전 식빵의 product_id : \u0027,goodsId_productId[94])\ngoodsId_productId[94] \u003d 37\nprint(\u0027교체 후 식빵의 product_id : \u0027,goodsId_productId[94])\n\n# 2. pickle 저장\n\nwith open(\u0027/DB_data/goodsId_productId.pickle\u0027,\u0027wb\u0027) as fw:\n    pickle.dump(goodsId_productId, fw)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nSELECT * FROM goods_price\nwhere goods_id\u003d94\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 2. 식빵의 unit_price를 10배하기\n+ 원래 100g가 단위용량인데, 10g로 계산되었음\n    + 590원 언저리이면, 잘 계산되어 있는 것임"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 식빵의 unit_price를 10배하기\n# 1. data load\nimport pandas as pd\ngoods_daily_price_pdf \u003d pd.read_csv(\u0027/DB_data/goods_daily_price_table.csv\u0027)\ntargets \u003d goods_daily_price_pdf[goods_daily_price_pdf[\u0027goods_id\u0027]\u003d\u003d94].index  # 식빵이 goods_id\u003d94\ngoods_daily_price_pdf.loc[targets, \u0027unit_price\u0027]*\u003d 10\ngoods_daily_price_pdf[goods_daily_price_pdf[\u0027goods_id\u0027]\u003d\u003d94]\n# goods_daily_price_pdf.to_csv(\u0027/DB_data/goods_daily_price_table.csv\u0027, header\u003dTrue, index\u003dFalse)\ngoods_daily_price_pdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 3. goods table에 goods_id\u003d94의 product_id를 37로 바꿔주기\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\nprop \u003d {\"user\": \"ji\", \"password\": \"cvgkbhs234r#8tdx\", \"driver\": \"com.mysql.cj.jdbc.Driver\"} \n#-----------------------------------------------------------------------------------------------------------------------------------------------------#\n#                                               1. common\n#-----------------------------------------------------------------------------------------------------------------------------------------------------#\n\n# 1. favorite_goods table (columns : user_id, goods_id) 가져온 후, 해당하는 user_id의 data만 가져오기\ngoods_sdf \u003d spark.read.format(\"jdbc\")\\\n    .option(\"url\", url) \\\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\n    .option(\"query\", f\"select * from goods\") \\\n    .option(\"user\", \"ji\")\\\n    .option(\"password\", \"cvgkbhs234r#8tdx\").load()\ngoods_sdf.show(n\u003d100)\n\n# 2. goods_id \u003d 94의 product_id를 37로 바꾸기\nfrom pyspark.sql.functions import col, when\ngoods_sdf \u003d goods_sdf.withColumn(\"product_id\", when(col(\u0027goods_id\u0027)\u003d\u003d94 , 37).otherwise(col(\u0027product_id\u0027)))\ngoods_sdf.show(n\u003d100)\n\n\n# 3. csv로 저장하기\n# goods_sdf.write.option(\"header\",\u0027true\u0027).option(\u0027index\u0027,\u0027false\u0027).csv(\u0027/DB_data/goods_table_tmp.csv\u0027)\ngoods_pdf \u003d goods_sdf.toPandas()\ngoods_pdf.to_csv(\u0027/DB_data/goods_table.csv\u0027,header\u003dTrue, index\u003dFalse)\ngoods_pdf\n\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}