{
  "metadata": {
    "name": "[monthly]01_product_price_table",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 6g\n\n# set executor number to be 3\nspark.executor.instances  4\n\n# set executor memory 4g\nspark.executor.memory  2g"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 1. daily data\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 1. daily data\nfrom pyspark.sql.functions import col\n# MySQL에 데이터 넣기 : 성공 (https://ko.n4zc.com/article/sa4p4m6e.html)\nprop \u003d {\"user\": \"ji\", \"password\": \"cvgkbhs234r#8tdx\", \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n   \n# product daily price table 읽기 \nproduct_daily_price_sdf \u003d spark.read.csv(\u0027/DB_data/product_daily_price_table.csv\u0027, header\u003dTrue, inferSchema\u003dTrue)\nproduct_daily_price_sdf.show()\n\n\n# # product daily price table 쓰기\n# product_daily_price_sdf.write.jdbc(\\\n#     url\u003d url,\\\n#     table \u003d \"product_price\",\\\n#     mode\u003d\"append\",\\\n#     properties\u003dprop)\n\n\n  \n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 2. month data\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 2. month data\nfrom pyspark.sql.functions import col\n# MySQL에 데이터 넣기 : 성공 (https://ko.n4zc.com/article/sa4p4m6e.html)\nprop \u003d {\"user\": \"ji\", \"password\": \"cvgkbhs234r#8tdx\", \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n   \n\n# product month price table 읽기 \nproduct_month_price_sdf \u003d spark.read.csv(\u0027/DB_data/product_month_price_table.csv\u0027, header\u003dTrue, inferSchema\u003dTrue)\nproduct_month_price_sdf.show()\n\n\n# product month price table 쓰기   \nproduct_month_price_sdf.write.jdbc(\\\n    url\u003d url,\\\n    table \u003d \"product_price\",\\\n    mode\u003d\"append\",\\\n    properties\u003dprop)  \n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nselect * from product_price\norder by product_price_id\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%MySQL\n"
    }
  ]
}