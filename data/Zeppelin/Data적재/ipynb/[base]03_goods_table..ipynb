{
  "metadata": {
    "name": "[base]03_goods_table",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 6g\n\n# set executor number to be 3\nspark.executor.instances  4\n\n# set executor memory 4g\nspark.executor.memory  2g"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pandas as pd\ngoods_sdf \u003d pd.read_csv(\u0027/DB_data/20221001_goods_table.csv\u0027)\ngoods_sdf[\u0027recent_price_off\u0027] \u003d 0\ngoods_sdf[\u0027recent_price_on\u0027] \u003d 0\ngoods_sdf[\u0027price_gap_off\u0027] \u003d 0\ngoods_sdf[\u0027price_gap_on\u0027] \u003d 0\ngoods_sdf.to_csv(\u0027/DB_data/20221001_goods_table.csv\u0027, index\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ngoods_sdf \u003d pd.read_csv(\u0027/DB_data/20221001_goods_table.csv\u0027)\ngoods_sdf"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col\n# MySQL에 데이터 넣기 : 성공 (https://ko.n4zc.com/article/sa4p4m6e.html)\nprop \u003d {\"user\": \"ji\", \"password\": \"cvgkbhs234r#8tdx\", \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n    \ngoods_sdf \u003d spark.read.csv(\u0027/DB_data/20221001_goods_table.csv\u0027, header\u003dTrue, inferSchema\u003dTrue)\ngoods_sdf \u003d goods_sdf.fillna({\u0027img\u0027:\u0027https://j7d108.p.ssafy.io/resource/logo.png\u0027})\n\ngoods_sdf.write.jdbc(\\\n    url\u003d url,\\\n    table \u003d \"goods\",\\\n    mode\u003d\"append\",\\\n    properties\u003dprop)\n    \n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nSELECT * FROM goods\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nselect * from product"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%MySQL\n"
    }
  ]
}