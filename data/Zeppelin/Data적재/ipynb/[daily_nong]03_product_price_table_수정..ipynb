{
  "metadata": {
    "name": "[daily_nong]03_product_price_table_수정",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 1. 농산물 데이터, 저녁에 새로 받아오면, \n+ ~~DBo_APIx , DBo_APIo, DBx_APIo 가져와서, 수정하기~~\n+ ~~DB의 goods_price table 갱신하기~~\n+ **DB의 product_price table 갱신하기** \n+ DB의 favorite_total_price table 갱신하기"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## [3]  DB의 product_price table의 해당 일자 농산물 mart data 지우고, 농산물만 groupBy 해서 넣기"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# 2HEQFFR9T\n# paragraph_1664893461293_1891832349\n# http://3.36.106.26:8081/api/notebook/run/2HEQFFR9T/paragraph_1664893461293_1891832349\n\n\n# 1. 날짜 선정\ntoday \u003d ( datetime.datetime.now()  + datetime.timedelta(hours\u003d9) ).strftime(\"%Y-%m-%d\")\n\n# 2. 새로 가져온 Data 가져오기\n## 2-1 : csv 로드\nnong_goods_price_m_pdf \u003d pd.read_csv(f\u0027/api_data/nong_goods_price_m_{today}.csv\u0027)\nnonnull_nong_goods_price_m_pdf \u003d nong_goods_price_m_pdf[nong_goods_price_m_pdf[\u0027price\u0027].notnull()]\n\n## 2-2 not null인 것 goods_id 가져오기\nnong_mart_goods_id_lst \u003d list(nonnull_nong_goods_price_m_pdf[\u0027goods_id\u0027])\n# print(nong_mart_goods_id_lst)\n\n\n## 3. DB에 갱신할 것 있으면 DB에서 갱신하기\nif len(nong_mart_goods_id_lst) !\u003d 0:\n    \n    ## 2. goodsId_productId pickle 가져오기\n    import pickle\n    with open(\u0027/DB_data/20221001_goodsId_productId.pickle\u0027, \u0027rb\u0027) as fr:\n        goodsId_productId \u003d pickle.load(fr)\n        \n    \n    ## 3. 해당되는 product_id 찾기\n    product_id_lst \u003d [ goodsId_productId[goods_id]  for goods_id in nong_mart_goods_id_lst]\n    print(\u0027groupBy할 prouct_id들  :  \u0027,product_id_lst)\n    \n    \n    ## 4. 해당 되는 product_id의 goods_id에 대해서만, groupBy 해서, product_price table 생성\n    \n    ### 4-1. productId_goodsId pickle 가져오기\n    import pickle\n    with open(\u0027/DB_data/20221001_productId_goodsId.pickle\u0027, \u0027rb\u0027) as fr:\n        productId_goodsId \u003d pickle.load(fr)\n    \n    ### 4-2. 계산해야할 product_id에 해당되는 goods_id 모두 가져와서 groupBy하기\n    will_be_grouped_goods_lst \u003d [ ]\n    for productId in product_id_lst:\n        goodsId_lst \u003d productId_goodsId[productId]\n        will_be_grouped_goods_lst +\u003d goodsId_lst\n    print(\u0027-\u0027*100)\n    print(\u0027groupBy할 goods_id들  :  \u0027, will_be_grouped_goods_lst)\n    will_be_grouped_goods_lst +\u003d [999999999999]\n    \n    ### 4-3. (1,)과 같은 형태 방지하기 위해서 길이가 1인경우 99999999999 더미데이터 추가\n    will_be_grouped_goods_tuple \u003d tuple(will_be_grouped_goods_lst) if len(will_be_grouped_goods_lst) \u003e\u003d2 else tuple(will_be_grouped_goods_lst+[999999999999])\n    \n    \n    ### 4-3. today의 will_be_grouped_goods_lst에 해당하는 data만 가져오기\n    url \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n    goods_price_sdf \u003d spark.read.format(\"jdbc\").option(\"url\", url).option(\"driver\", \"com.mysql.cj.jdbc.Driver\").option(\"query\", f\"select * from goods_price where research_date\u003d\u0027{today}\u0027 and goods_id in {will_be_grouped_goods_tuple}\").option(\"user\", \"ji\").option(\"password\", mysql_password).load()\n    # goods_price_sdf.show()\n    \n    \n    ### 4-4. product_id column 생성\n    goods_price_pdf \u003d goods_price_sdf.toPandas()\n    goods_price_pdf \u003d goods_price_pdf.reset_index(drop\u003dTrue)\n    # print(goods_price_pdf)\n    import pickle\n    with open(\u0027/DB_data/20221001_goodsId_productId.pickle\u0027, \u0027rb\u0027) as fr:\n        goodsId_productId \u003d pickle.load(fr)    \n    product_id_lst \u003d []\n    for i in range(len(goods_price_pdf)):\n        goods_id \u003d goods_price_pdf.loc[i,\u0027goods_id\u0027]\n        product_id \u003d goodsId_productId[goods_id]\n        product_id_lst.append(product_id)\n    \n    goods_price_pdf[\u0027product_id\u0027] \u003d product_id_lst\n    goods_price_sdf_with_product \u003d spark.createDataFrame(goods_price_pdf)\n    goods_price_sdf_with_product.show()\n    \n    ### 4-5. product_price table 생성\n    from pyspark.sql.functions import col, avg, round, lit\n    product_price_sdf \u003d goods_price_sdf_with_product.groupBy(\u0027product_id\u0027,\u0027research_date\u0027,\u0027business\u0027).agg( round( avg(col(\u0027unit_price\u0027)) ,2).alias(\u0027unit_price\u0027)  ,  round(  avg(col(\u0027price\u0027)), 2) .alias(\u0027price\u0027)  )\n    product_price_sdf \u003d product_price_sdf.withColumn(\u0027date_type\u0027,lit(\u0027d\u0027))\n    # product_price_sdf.show()\n    product_price_sdf \u003d product_price_sdf.select(\u0027product_id\u0027,\u0027unit_price\u0027,\u0027price\u0027,\u0027research_date\u0027,\u0027date_type\u0027,\u0027business\u0027)\n    print(\u0027[아래] DB에 넣을 product_price table --------------------------------------\u0027)\n    product_price_sdf.show()\n    \n    \n    \n    ### 4-6. DB에서 해당 product_price 삭제\n    import requests\n    url \u003d \"http://3.36.106.26:8081/api/notebook/run/2HEQFFR9T/paragraph_1664889579484_1213402996\"\n    \n    product_id_lst +\u003d [99999999999999]\n    product_id_tuple \u003d tuple(product_id_lst)\n    \n    req \u003d requests.post(url, json\u003d{\"params\": {\"product_id_tuple\": str(product_id_tuple) , \"research_date\": today } } )\n    import time\n    time.sleep(1)\n    \n    \n    ### 4-7. DB에 해당 product_price 넣기\n    prop \u003d {\"user\": \"ji\", \"password\": mysql_password, \"driver\": \"com.mysql.cj.jdbc.Driver\"} \n    url \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n    product_price_sdf.write.jdbc(url\u003d url, table \u003d \"product_price\", mode\u003d\"append\", properties\u003dprop)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\ndelete from product_price\nwhere product_id in ${product_id_tuple} and research_date \u003d\u0027${research_date}\u0027\n"
    }
  ]
}