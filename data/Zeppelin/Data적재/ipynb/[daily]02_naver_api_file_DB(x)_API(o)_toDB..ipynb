{
  "metadata": {
    "name": "[daily]02_naver_api_file_DB(x)_API(o)_toDB",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " # 1. DB(x) \u0026 API(o) 인, 데이터 넣기\nautomation으로 가져온 것 DB에 넣기 전, 전처리\n+ 처음 DB에 넣는 경우,  2021년 09월07일부터 ~ 측정일까지 채워넣어서, DB에 넣기\n    +  ONLINE DATA \n    + 처음 넣는 데이터들 "
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 8g\n\n# set executor number to be 3\nspark.executor.instances  3\n\n# set executor memory 4g\nspark.executor.memory  2g\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## [1] 처음 DB에 넣는 데이터인지 확인(전체 goods_id에 대해서 진행)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (1) 데이터 채울 때, 사용할 함수\n1. row 방향 날짜 데이터(일단위아님)를, 일데이터 주기로 바꾸기\n+ column\n    + goods_id, unit_price,  price, research_date, business로 구성되어 있음\n+ 제약사항\n    + business 값이 모두 같은 경우에만 정상작동함 "
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 함수 정의\n\nimport datetime\nimport numpy as np\nimport pandas as pd\n\n# row 형식으로 된, 일데이터 주기가 아닌 데이터를, 일데이터 형식으로 바꾸기\ndef inserting_date(start_date, end_date, input_df, business): # Pandas DF를 이용\n    print(\u0027debug1\u0027)\n    \n    #---------------------------------------------------------------------------------------------------------------------------------#\n    #                 1. 초기작업 : 결과 df 생성, 초기값들 설정\n    #---------------------------------------------------------------------------------------------------------------------------------#\n\n    \n    # 초기 설정 값\n    start_goods_id \u003d min((input_df[\u0027goods_id\u0027]))\n    # print(\u0027d1\u0027)\n    end_goods_id \u003d max((input_df[\u0027goods_id\u0027]))\n    # print(\u0027d2\u0027)\n    cur_goods_id \u003d start_goods_id - 1\n    # print(\u0027d3\u0027)\n    cur_research_date \u003d start_date\n    # print(\u0027debug2\u0027)\n    \n    \n    # goods_id, research_date 기준으로 sorting 시키기\n    input_df \u003d input_df.reset_index(drop\u003dTrue)\n    input_df \u003d input_df.sort_values([\u0027goods_id\u0027,\u0027research_date\u0027])\n    # 추후에 삭제할 행\n    input_df.loc[len(input_df)] \u003d [end_goods_id+1, 0, 0 ,start_date.strftime(\"%Y-%m-%d\"), business]\n    print(\u0027debug3\u0027)\n    \n    # result\n    result_df \u003d pd.DataFrame(columns\u003dinput_df.columns)\n    inserting_length \u003d 0\n    \n    \n    \n    input_df_length \u003d 0\n    # input_df의 끝까지 가지 않은 경우, 계속하기\n    ## 1. goods_id 가 달라지는 경우, research_date가 일치하면, input_df_length를 1 늘리기\n    while input_df_length \u003c len(input_df): # dummy row까지 쭉 진행,\n    \n        next_goods_id, next_unit_price, next_price, next_research_date, next_business \u003d input_df.loc[input_df_length]   # input_df의 다음(목표) row\n        # inserting_research_date \u003d cur_research_date                                                    # input_df의 현재 row\n    \n        \n        # goods_id가 같은 경우\n        if next_goods_id \u003d\u003d cur_goods_id:\n            ## input_df의 next row에 도달한 경우, 도달한 값 넣어주기\n    \n    \n\n            # print(\u0027debug 3\u0027)\n            ## 현재 inserting 날짜가, next_research_date에 도달하기 전까지 , 계속 row 삽입하기\n            while next_research_date !\u003d inserting_research_date.strftime(\"%Y-%m-%d\"):\n                # print(inserting_research_date.strftime(\"%Y-%m-%d\"), \u0027--------------------\u0027)\n                result_df.loc[inserting_length] \u003d cur_goods_id, cur_unit_price, cur_price, inserting_research_date.strftime(\"%Y-%m-%d\"),  cur_business\n                \n                \n                cur_research_date \u003d inserting_research_date                        # cur_research_date 업데이트\n                \n\n                inserting_research_date +\u003d  datetime.timedelta(days\u003d1) # inserting할 날짜 늘리기\n                inserting_length +\u003d 1   # result_df 길이 추가\n                \n            cur_goods_id \u003d next_goods_id                                       # cur_goods_id 업데이트\n            cur_unit_price \u003d next_unit_price\n            cur_price \u003d next_price                                             # cur_price 업데이트\n            cur_business \u003d next_business                                       # cur_business 업데이트\n            input_df_length +\u003d 1\n                \n    \n           \n    \n    \n        # 새로운 goods_id를 넣는 경우, 새로 진행\n        elif next_goods_id !\u003d cur_goods_id:\n            print(cur_goods_id) if cur_goods_id % 10 \u003d\u003d0\n            # print(result_df)\n            \n            ## end_date 까지 row 채워주기\n            if cur_goods_id !\u003d start_goods_id - 1:  # 처음 시작하는 경우가 아니라면,\n                while end_date + datetime.timedelta(days\u003d1) \u003e inserting_research_date:\n                    result_df.loc[inserting_length] \u003d cur_goods_id, cur_unit_price,cur_price, inserting_research_date.strftime(\"%Y-%m-%d\"),  cur_business\n                    inserting_research_date +\u003d  datetime.timedelta(days\u003d1) # inserting할 날짜 늘리기\n                    inserting_length +\u003d 1   # result_df 길이 추가\n            \n            ## input_df의 마지막까지 진행됐다면 while문 break해서 끝내기\n            if input_df_length \u003d\u003d len(input_df) - 1:\n                print(\u0027here\u0027)\n                break\n            \n            ## inserting_research_date 초기화\n            inserting_research_date \u003d start_date\n            \n            ## 만약 첫 row가 start_date일이 아니면, 채워주기\n            inserting_unit_price \u003d next_unit_price\n            inserting_price \u003d next_price  # next_price의 가격을 앞에 채워주기\n            ### 다음 row의 날짜에 도달하기 전까지 계속 추가해 주기\n            while next_research_date !\u003d inserting_research_date.strftime(\"%Y-%m-%d\"):\n                result_df.loc[inserting_length] \u003d next_goods_id, next_unit_price, inserting_price, inserting_research_date.strftime(\"%Y-%m-%d\"), next_business\n                # print(inserting_research_date.strftime(\"%Y-%m-%d\"),\u0027\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u0027)\n                \n                cur_research_date \u003d inserting_research_date                        # cur_research_date 업데이트\n                \n                \n                inserting_research_date +\u003d  datetime.timedelta(days\u003d1) # inserting할 날짜 늘리기\n                inserting_length +\u003d 1   # result_df 길이 추가\n            \n            input_df_length +\u003d 1    # input_df 길이 추가\n            cur_goods_id \u003d next_goods_id                                       # cur_goods_id 업데이트\n            cur_unit_price \u003d next_unit_price\n            cur_price \u003d next_price                                             # cur_price 업데이트\n            \n            cur_business \u003d next_business                                       # cur_business 업데이트\n            \n    return result_df\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 2. 사용 예시\nstart_date \u003d datetime.date(2021,9,7)\nend_date \u003d datetime.date(2022,9,30)\ninput_df \u003d pd.read_csv(\u0027/DB_data/goods_price_table_0926.csv\u0027)\ninput_df1 \u003d input_df[ (input_df[\u0027goods_id\u0027]\u003e\u003d0) \u0026 (input_df[\u0027goods_id\u0027]\u003c300) \u0026 (input_df[\u0027business\u0027]\u003d\u003d\u0027s\u0027) ]\ninput_df2 \u003d input_df[ (input_df[\u0027goods_id\u0027]\u003e\u003d300) \u0026 (input_df[\u0027business\u0027]\u003d\u003d\u0027s\u0027)  ]"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (2) goods_price table 검색\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pandas as pd\nfrom pyspark.sql.functions import col\nimport datetime\n\n# 1. 결과 df 생성\nresult_df \u003d pd.DataFrame(columns\u003d[\u0027goods_id\u0027, \u0027unit_price\u0027, \u0027price\u0027, \u0027research_date\u0027, \u0027business\u0027])\n\n\n# 2. DB 정보 및 Load\nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n## 2-1 goods_price\ngoods_price_sdf \u003d spark.read.format(\"jdbc\")\\\n    .option(\"url\", url) \\\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\n    .option(\"query\", \"select goods_id, unit_price, price, research_date, business from goods_price\") \\\n    .option(\"user\", \"ji\")\\\n    .option(\"password\", mysql_password).load()\n    \n## db Data를 pandas로 바꾸기\ngoods_price_mart_sdf \u003d goods_price_sdf.filter(col(\u0027business\u0027)\u003d\u003d\u0027m\u0027)\ngoods_price_mart_pdf \u003d goods_price_mart_sdf.toPandas()\ngoods_price_ssm_sdf \u003d goods_price_sdf.filter(col(\u0027business\u0027)\u003d\u003d\u0027s\u0027)\ngoods_price_ssm_pdf \u003d goods_price_ssm_sdf.toPandas()\ngoods_price_online_sdf \u003d goods_price_sdf.filter(col(\u0027business\u0027)\u003d\u003d\u0027o\u0027)\ngoods_price_online_pdf \u003d goods_price_online_sdf.toPandas()\n\n\n## 기존 DB에 있는 goods_id들\nDB_goods_id_mart \u003d set(goods_price_mart_pdf[\u0027goods_id\u0027].unique())\nDB_goods_id_ssm \u003d set(goods_price_ssm_pdf[\u0027goods_id\u0027].unique())\nDB_goods_id_online \u003d set(goods_price_online_pdf[\u0027goods_id\u0027].unique())\n\n\n\n# goods_price_online_sdf.show()\n\n## 2-2 goods id\ngoods_id_sdf \u003d spark.read.format(\"jdbc\")\\\n    .option(\"url\", url) \\\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\n    .option(\"query\", \"select goods_id from goods\") \\\n    .option(\"user\", \"ji\")\\\n    .option(\"password\", mysql_password).load()\n\ngoods_id_pdf \u003d goods_id_sdf.toPandas()\ngoods_id_lst \u003d list(goods_id_pdf[\u0027goods_id\u0027])\n\n\n# 3. 날짜 설정\nstart_date \u003d datetime.date(2021,9,7)\nend_date \u003d datetime.datetime.now().date()\n\ntoday \u003d datetime.datetime.now().strftime(\u0027%Y%m%d\u0027)\nyesterday \u003d datetime.datetime.now() - datetime.timedelta(days\u003d1)\nyesterday \u003d yesterday.strftime(\u0027%Y-%m-%d\u0027)\nprint(today, yesterday)\n\n\n# 4. 추가할 csv Load\nnew_goods_price_mart_pdf \u003d pd.read_csv(f\u0027/naverapi_data/goods_price_m_{today}.csv\u0027)\nnew_goods_price_ssm_pdf \u003d pd.read_csv(f\u0027/naverapi_data/goods_price_s_{today}.csv\u0027)\nnew_goods_price_online_pdf \u003d pd.read_csv(f\u0027/naverapi_data/goods_price_o_{today}.csv\u0027)\n\nmart_goods_id_set \u003d set(new_goods_price_mart_pdf[\u0027goods_id\u0027])\nssm_goods_id_set \u003d set(new_goods_price_ssm_pdf[\u0027goods_id\u0027])\nonline_goods_id_set \u003d set(new_goods_price_online_pdf[\u0027goods_id\u0027])\n\n\n# 5. 추가할 csv 각각 DB 탐색 \u003d\u003e 넣을 데이터가 DB에 없는 경우 파악\nmart_input_df \u003d pd.DataFrame(columns\u003d[\u0027goods_id\u0027, \u0027unit_price\u0027, \u0027price\u0027, \u0027research_date\u0027, \u0027business\u0027])\nssm_input_df \u003d pd.DataFrame(columns\u003d[\u0027goods_id\u0027, \u0027unit_price\u0027, \u0027price\u0027, \u0027research_date\u0027, \u0027business\u0027])\nonline_input_df \u003d pd.DataFrame(columns\u003d[\u0027goods_id\u0027, \u0027unit_price\u0027, \u0027price\u0027, \u0027research_date\u0027, \u0027business\u0027])\n\n\nmart_length \u003d 0\nssm_length \u003d 0\nonline_length \u003d 0\nfor goods_id in goods_id_lst:\n    ## [1] mart\n    ### (1) mart 데이터를 받아 왔는데,\n    if goods_id in mart_goods_id_set:\n        ### (a) mart DB에 없는 경우 \u003d\u003e mart_input_df 넣어줘야 함\n        if goods_id not in DB_goods_id_mart:\n            mart_input_df.loc[mart_length] \u003d list(new_goods_price_mart_pdf[new_goods_price_mart_pdf[\u0027goods_id\u0027]\u003d\u003dgoods_id].iloc[0].values)\n            mart_length+\u003d1\n\n    ## [2] ssm\n    ### (1) ssm 데이터를 받아 왔는데,\n    if goods_id in ssm_goods_id_set:\n        ### (a) ssm DB에 없는 경우 \u003d\u003e ssm_input_df 넣어줘야 함\n        if goods_id not in DB_goods_id_ssm:\n            ssm_input_df.loc[ssm_length] \u003d list(new_goods_price_ssm_pdf[new_goods_price_ssm_pdf[\u0027goods_id\u0027]\u003d\u003dgoods_id].iloc[0].values)\n            ssm_length+\u003d1\n\n    ## [3] online\n    ### (1) online 데이터를 받아 왔는데,\n    if goods_id in online_goods_id_set:\n        ### (a) online DB에 없는 경우 \u003d\u003e online_input_df 넣어줘야 함\n        if goods_id not in DB_goods_id_online:\n            online_input_df.loc[online_length] \u003d list(new_goods_price_online_pdf[new_goods_price_online_pdf[\u0027goods_id\u0027]\u003d\u003dgoods_id].iloc[0].values)\n            online_length+\u003d1\n\n\n\n    \n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 6. DB에 넣을 DF 생성        \nmart_result_df \u003d inserting_date(start_date, end_date, mart_input_df,\u0027m\u0027)\n# ssm_result_df \u003d inserting_date(start_date, end_date, ssm_input_df,\u0027s\u0027)\n# online_result_df \u003d inserting_date(start_date, end_date, online_input_df,\u0027o\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# 6. DB에 넣을 DF 생성        \n# mart_result_df \u003d inserting_date(start_date, end_date, mart_input_df,\u0027m\u0027)\nssm_result_df \u003d inserting_date(start_date, end_date, ssm_input_df,\u0027s\u0027)\n# online_result_df \u003d inserting_date(start_date, end_date, online_input_df,\u0027o\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# 6. DB에 넣을 DF 생성        \n# mart_result_df \u003d inserting_date(start_date, end_date, mart_input_df,\u0027m\u0027)\n# ssm_result_df \u003d inserting_date(start_date, end_date, ssm_input_df,\u0027s\u0027)\nonline_result_df1 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d0  ) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c50)  ],\u0027o\u0027)\nonline_result_df2 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d50 ) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c100)  ],\u0027o\u0027)\nonline_result_df3 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d100) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c150)  ],\u0027o\u0027)\nonline_result_df4 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d150) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c200)  ],\u0027o\u0027)\nonline_result_df5 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d200) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c250)  ],\u0027o\u0027)\nonline_result_df6 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d250) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c300)  ],\u0027o\u0027)\nonline_result_df7 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d300) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c350)  ],\u0027o\u0027)\nonline_result_df8 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d350) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c400)  ],\u0027o\u0027)\nonline_result_df9 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d400) \u0026  (online_input_df[\u0027goods_id\u0027]\u003c500)  ],\u0027o\u0027)\nonline_result_df10 \u003d inserting_date(start_date, end_date, online_input_df[ (online_input_df[\u0027goods_id\u0027] \u003e\u003d20000)                                     ],\u0027o\u0027)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### 주의! 아래는 DB에 넣는 부분"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col, isnan\nprop \u003d {\"user\": \"ji\", \"password\": mysql_password, \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n\n# 7. DB에 넣기 ( DB에는 없고, NAVER API에는 있는 것들 모두 넣기)\nresults \u003d [\nmart_result_df,\nssm_result_df\n]\nfor pdf in results:\n    # print(pdf)\n    sdf \u003d spark.createDataFrame(pdf)\n    sdf \u003d sdf.filter(~isnan(col(\u0027price\u0027)))\n    sdf.write.jdbc(\\\n    url\u003d url,\\\n    table \u003d \"goods_price\",\\\n    mode\u003d\"append\",\\\n    properties\u003dprop)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import col, isnan\nprop \u003d {\"user\": \"ji\", \"password\": mysql_password, \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n\n# 7. DB에 넣기 ( 우선 null인 것들은 모두 제외하고 넣어주기)\nresults \u003d [\n#mart_result_df,\n#ssm_result_df,\nonline_result_df1,\nonline_result_df2,\nonline_result_df3,\nonline_result_df4,\nonline_result_df5,\nonline_result_df6,\nonline_result_df7,\nonline_result_df8,\nonline_result_df9,\nonline_result_df10\n]\nfor pdf in results:\n    # print(pdf)\n    sdf \u003d spark.createDataFrame(pdf)\n    sdf \u003d sdf.filter(~isnan(col(\u0027price\u0027)))\n    # sdf.write.jdbc(\\\n    # url\u003d url,\\\n    # table \u003d \"goods_price\",\\\n    # mode\u003d\"append\",\\\n    # properties\u003dprop)\n\n    "
    }
  ]
}