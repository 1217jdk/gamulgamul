{
  "metadata": {
    "name": "datetime_and_dateutil",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 8g\n\n# set executor number to be 3\nspark.executor.instances  3\n\n# set executor memory 4g\nspark.executor.memory  2g"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 1. datetime 날짜 더하기"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n### (1) weeks 이하 가능 : microseconds, milliseconds, seconds, minutes, hours, days, weeks로  가능\nimport datetime\n\nstart_date \u003d datetime.date(2022,9,7)\nprint(type(start_date))\nprint(start_date)\nstart_date +\u003d  datetime.timedelta(days\u003d1) # \nprint(start_date)\n\n\n### (2) year 이하 가능 : microseconds, milliseconds, seconds, minutes, hours, days, weeks, months, years 로  가능\nfrom dateutil.relativedelta import relativedelta\nnow \u003d datetime.datetime.now()\nafter_one_day \u003d now + relativedelta(days\u003d1)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2. datetime -\u003e str \u0026 str -\u003e datetime\n+\n+ str -\u003e datetime [참조링크](https://www.digitalocean.com/community/tutorials/python-string-to-datetime-strptime)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport datetime\n\n# datetime\nstart_date \u003d datetime.date(2022,9,7)\nprint(start_date, type(start_date))\n\n# datetime -\u003e string\nstart_date_str \u003d start_date.strftime(\"%Y-%m-%d\")\nprint(start_date_str, type(start_date_str))\n\n\n# string -\u003e datetime\nstart_date \u003d datetime.datetime.strptime(start_date_str, \"%Y-%m-%d\").date()\nprint(start_date, type(start_date))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}