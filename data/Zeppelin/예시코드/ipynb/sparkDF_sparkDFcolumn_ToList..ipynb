{
  "metadata": {
    "name": "sparkDF_sparkDFcolumn_ToList",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (1) sparkDF의 column 값을 python list로 바꾸기 - 방법 1\n+ https://www.geeksforgeeks.org/converting-a-pyspark-dataframe-column-to-a-python-list/"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n### 1개 column 변환\nthird_sdf_product_rename.select(\u0027product_name\u0027).distinct().rdd.flatMap(lambda x: x).collect()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n### 여러 colunmn 한번에 하기\ndataframe.select([\u0027student Name\u0027,\n                        \u0027student Name\u0027,\n                        \u0027college\u0027]).\n      rdd.flatMap(lambda x: x).collect())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 방법 2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfull_favorite_goods_sdf.select(\u0027user_id\u0027).distinct().show()\ndistinct_ids \u003d [x.user_id for x in full_favorite_goods_sdf.select(\u0027user_id\u0027).distinct().collect()]\nprint(distinct_ids)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}