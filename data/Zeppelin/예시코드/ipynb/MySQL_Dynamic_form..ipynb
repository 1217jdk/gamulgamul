{
  "metadata": {
    "name": "MySQL_Dynamic_form",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nSPARK_HOME  /usr/local/spark\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3\n\n# set driver memory to 8g\nspark.driver.memory 8g\n\n# set executor number to be 3\nspark.executor.instances  3\n\n# set executor memory 4g\nspark.executor.memory  2g"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nUPDATE goods SET cheap_url \u003d \u0027${cheap_url}\u0027 WHERE goods_id \u003d CAST(\u0027${goods_id}\u0027 AS UNSIGNED);"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (2) f string과 함께 쓰는 방법\n+ f\"\u0027{z.textbox()}\u0027\""
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# 1. 시작날짜와 끝 날짜 정하기\n\nstart_day \u003d z.textbox(\u0027start_day\u0027)\nend_day \u003d z.textbox(\u0027end_day\u0027)\n\n\n# start_day \u003d \u00272022-09-01\u0027\n# end_day \u003d \u00272022-09-03\u0027\n\n\n\n# 2. DB 정보\nprop \u003d {\"user\": \"ji\", \"password\": \"cvgkbhs234r#8tdx\", \"driver\": \"com.mysql.cj.jdbc.Driver\"} \nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\n\n# 3. goods_price table 가져오기\ngoods_price_sdf \u003d spark.read.format(\"jdbc\")\\\n    .option(\"url\", url ) \\\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\n    .option(\"query\", f\"select goods_id, unit_price, price, research_date, business from goods_price where research_date \u003e\u003d \u0027{start_day}\u0027 and research_date\u003c\u003d\u0027{end_day}\u0027\") \\\n    .option(\"user\", \"ji\")\\\n    .option(\"password\", \"cvgkbhs234r#8tdx\").load()\n\ngoods_price_sdf.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (3) tuple 넣는법\n+ goods_id_tuple \u003d \u0027(1,2,3,4)\u0027 : type is str\n+ research_date is \u002720221004\u0027 : type is str"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%MySQL\nselect * from goods_price\nwhere goods_id in ${goods_id_tuple} and research_date \u003d${research_date}"
    }
  ]
}