{
  "metadata": {
    "name": "5개_테이블_로컬에저장",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nimport datetime\r\ntoday \u003d \u002720221004\u0027\r\nprint(today)\r\n\r\nurl \u003d \"jdbc:mysql://j7d108.p.ssafy.io:3306/gamulgamul_test3?useSSL\u003dfalse\u0026characterEncoding\u003dUTF-8\u0026useUnicode\u003dtrue\u0026allowPublicKeyRetrieval\u003dtrue\u0026serverTimezone\u003dAsia/Seoul\"\r\n\r\n# 1. 읽기 \u0026 Local에 저장\r\n\r\ncategory_sdf \u003d spark.read.format(\"jdbc\")\\\r\n    .option(\"url\", url) \\\r\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\r\n    .option(\"query\", \"select * from category\")\\\r\n    .option(\"user\", \"ji\")\\\r\n    .option(\"password\", mysql_password).load()\r\n\r\ncategory_pdf \u003d category_sdf.toPandas()\r\ncategory_pdf.to_csv(f\u0027/DB_data/{today}_category_table.csv\u0027, index\u003dFalse, header\u003dTrue)\r\nprint(category_pdf)\r\n\r\n\r\nproduct_sdf \u003d spark.read.format(\"jdbc\")\\\r\n    .option(\"url\", url) \\\r\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\r\n    .option(\"query\", \"select * from product\")\\\r\n    .option(\"user\", \"ji\")\\\r\n    .option(\"password\", mysql_password).load()\r\nproduct_pdf \u003d product_sdf.toPandas()\r\nproduct_pdf.to_csv(f\u0027/DB_data/{today}_product_table.csv\u0027 , index\u003dFalse, header\u003dTrue)\r\nprint(product_pdf)\r\n\r\n\r\ngoods_sdf \u003d spark.read.format(\"jdbc\")\\\r\n    .option(\"url\", url) \\\r\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\r\n    .option(\"query\", \"select * from goods\")\\\r\n    .option(\"user\", \"ji\")\\\r\n    .option(\"password\", mysql_password).load()\r\ngoods_pdf \u003d goods_sdf.toPandas()  \r\ngoods_pdf.to_csv(f\u0027/DB_data/{today}_goods_table.csv\u0027 , index\u003dFalse, header\u003dTrue)\r\nprint(goods_pdf)\r\n\r\n\r\nproduct_price_sdf \u003d spark.read.format(\"jdbc\")\\\r\n    .option(\"url\", url) \\\r\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\r\n    .option(\"query\", \"select * from product_price\")\\\r\n    .option(\"user\", \"ji\")\\\r\n    .option(\"password\", mysql_password).load()\r\nproduct_price_pdf \u003d product_price_sdf.toPandas()    \r\nproduct_price_pdf \u003d product_price_pdf.drop(\u0027product_price_id\u0027, axis\u003d1)\r\nproduct_price_pdf.to_csv(f\u0027/DB_data/{today}_product_price_table.csv\u0027 , index\u003dFalse, header\u003dTrue)\r\nprint(product_price_pdf)\r\n\r\n\r\ngoods_price_sdf \u003d spark.read.format(\"jdbc\")\\\r\n    .option(\"url\", url) \\\r\n    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\r\n    .option(\"query\", \"select * from goods_price\")\\\r\n    .option(\"user\", \"ji\")\\\r\n    .option(\"password\", mysql_password).load()\r\ngoods_price_pdf \u003d goods_price_sdf.toPandas()     \r\ngoods_price_pdf \u003d goods_price_pdf.drop(\u0027goods_price_id\u0027, axis\u003d1)\r\ngoods_price_pdf.to_csv(f\u0027/DB_data/{today}_goods_price_table.csv\u0027 , index\u003dFalse, header\u003dTrue)\r\nprint(goods_price_pdf)\r\n\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}